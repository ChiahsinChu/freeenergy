% !TeX spellcheck = en_US
\subsection{Bennett Acceptance Ratio\label{Sec:FEM:BAR}}
\begin{chapquote}{Professor Savas Dimopoulos, Stanford University}
	``The thing that differentiates scientists is purely an artistic ability to discern what is a good idea, what is a beautiful idea, what is worth spending time on, and most importantly, what is a problem that is sufficiently interesting, yet sufficiently difficult, that is hasn't yet been solved, but the time for solving it has come now.''
\end{chapquote}
Bennett acceptance ratio was developed by Bennett in 1976,\cite{BennettJComputPhys1976} and was re-discovered by Crooks\cite{CrooksPRE2000} and Shirts et al\cite{ShirtsPRL2003} using maximum likelihood over 20 years later. The Metropolis function is defined as
\begin{equation}
	M(x)=min\{1,\exp{(-x)}\},
\end{equation}
which has the property 
\begin{equation}
	M(x)/M(-x)=\exp{(-x)}.
\end{equation}

If we make a trial move that keeps the same configuration ($q_{1},\cdots,q_{N}$)
but switches the potential function from $U_{0}$ to $U_{1}$ or vice-versa, 
the acceptance probabilities for such a pair of trial moves must satisfy
the detailed balance
\begin{equation}
	M(U_{1}-U_{0})\exp{(-U_{0})}=M(U_{0}-U_{1})\exp{(-U_{1})}.
\end{equation}

Integrating this identity over all of configuration space and multiplying
by the trivial factors $Q_{0}/Q_{0}$ and $Q_{1}/Q_{1}$, one obtains:

\begin{equation}
	Q_{0}\frac{\int M(U_{1}-U_{0})\exp{(-U_{0})}\diff\mathbf{{q}}}{Q_{0}}=Q_{1}\frac{\int M(U_{0}-U_{1})\exp{(-U_{1})}\diff\mathbf{{q}}}{Q_{1}},
\end{equation}
or simply

\begin{equation}
	\frac{Q_{0}}{Q_{1}}=\frac{<M(U_{0}-U_{1})>_{1}}{<M(U_{1}-U_{0})>_{0}}.\label{eq:FEM:BAR:MetropolisRatio}
\end{equation}

The physical meaning of this formula is that a Monte Carlo calculation
that includes potential-switching trial moves would distribute configurations
between $U_{1}$ and $U_{0}$ in the ratio of their configurational
integrals. 

A formula more general than Eq.~\ref{eq:FEM:BAR:MetropolisRatio} can be written
as
\begin{equation}
	\frac{Q_{0}}{Q_{1}}=\frac{Q_{0}}{Q_{1}}\frac{\int W\exp{(-U_{0}-U_{1})}\diff\mathbf{{q}}}{\int W\exp{(-U_{1}-U_{0})}\diff\mathbf{{q}}}=\frac{\langle W\exp{(-U_{0})}\rangle_{1}}{\langle W\exp{(-U_{1})}\rangle_{0}},\label{eq:FEM:BAR:weightedratio}
\end{equation}
where $W$ is an arbitrary weighting function.

Optimization of the free energy estimate is most easily carried out in the limit of large sample sizes. Let the available data consist
of $n_{0}$ statistically independent configurations from the $U_{0}$ ensemble and $n_{1}$ from the $U_{1}$ ensemble, and let the data
be used in Eq.~\ref{eq:FEM:BAR:weightedratio} to obtain a finite-sample estimate of the reduced free energy difference $\Delta A=A_{1}-A_{0}=\ln{(Q_{0}/Q_{1})}$.
Using the error propagation law of uncorrelated variables ($covar(x_1,x_2)=0$),\cite{BerendsenBook2011}
\begin{equation}
	\delta^2\left[y(x_{1},x_{2})\right]=\left(\frac{\partial y}{\partial x_{1}}\right)^{2}\delta^2(x_{1})+\left(\frac{\partial y}{\partial x_{2}}\right)^{2}\delta^2(x_{2}).
\end{equation}

Thus we have the variance of $\Delta A$
\begin{eqnarray}
	\delta^2(\Delta A) & = & \left(\frac{\partial\Delta A}{\partial Q_{0}}\right)^{2}\delta^2Q_0+\left(\frac{\partial\Delta A}{\partial Q_{1}}\right)^{2}\delta^2Q_1\notag\\
	& = & \left(\frac{1}{Q_{0}}\right)^{2}\delta^2Q_0+\left(-\frac{1}{Q_{1}}\right)^{2}\delta^2Q_1\notag\\
	& = & \left(\frac{1}{Q_{0}}\right)^{2}\delta^2Q_0+\left(\frac{1}{Q_{1}}\right)^{2}\delta^2Q_1.
\end{eqnarray}

With the definition of variance $\delta^2X=\left\langle X^{2}\right\rangle -\left\langle X\right\rangle ^{2}$,
we have 
\begin{eqnarray}
	\delta^2Q_0 & = & \delta^2\left\langle W\exp{(-U_{0})}\right\rangle_{1}\notag\\
	& = & \delta^2\left(\frac{1}{n_1}\sum_{i=1}^{n_1}W_{i}\exp{\left(-U_{0}(i)\right)}\right)\notag\\
	& = & \sum_{i=1}^{n_{1}}\left(\frac{1}{n_{1}}\right)^{2}\delta^2\left(W_{i}\exp{\left(-U_{0}(i)\right)}\right)\notag\\
	& = & \frac{1}{n_{1}}\delta^2\left(W_{i}\exp{\left(-U_{0}(i)\right)}\right)\notag\\
	& = & \frac{1}{n_{1}}\left\{ \left< \left[W\exp{(-U_{0})}\right]^{2}\right>_{1}-\left[\left< W\exp{(-U_{0})}\right>_{1}\right]^{2}\right\}\notag\\
	& = & \frac{1}{n_{1}}\left\{ \left< W^{2}\exp{(-2U_{0})}\right>_{1}-\left[\left< W\exp{(-U_{0})}\right>_{1}\right]^{2}\right\},
\end{eqnarray}
which shows that the variance of the mean of the samples equals to the variance of the samples divided by the number of samples.

With sufficiently large sample sizes, the error of this estimate will
be nearly Gaussian, and its expected square is exactly the variance
of $\Delta A$ 
\begin{align}
	\delta^2 & (\Delta A_{est}-\Delta A)\nonumber \\
	\approx & \frac{\langle W^{2}\exp{(-2U_{1})}\rangle_{0}}{n_{0}[\langle W\exp{(-U_{1})}\rangle_{0}]^{2}}+\frac{\langle W^{2}\exp{(-2U_{0})}\rangle_{1}}{n_{1}[\langle W\exp{(-U_{0})}\rangle_{1}]^{2}}-\frac{1}{n_{0}}-\frac{1}{n_{1}}\nonumber \\
	= & \frac{\int\left[(Q_{0}/n_{0})\exp{(-U_{1})}+(Q_{1}/n_{1})\exp{(-U_{0})}\right]W^{2}\exp{(-U_{0}-U_{1})}\diff\mathbf{q}}{[\int W\exp{(-U_{0}-U_{1})}\diff\mathbf{q}]^{2}}\notag\\
	  &-\frac{1}{n_{0}}-\frac{1}{n_{1}}.\label{eq:FEM:BAR:expectation}
\end{align}

To minimize it with respect to $W$, we have
\begin{equation}
	W=const\times\left(\frac{Q_{0}}{n_{0}}\exp{(-U_{1})}+\frac{Q_{1}}{n_{1}}\exp{(-U_{0})}\right)^{-1}.
	\label{eq:FEM:BAR:W}
\end{equation}

Substituting this into Eq.~\ref{eq:FEM:BAR:weightedratio} yields
\begin{equation}
	\frac{Q_{0}}{Q_{1}}=\frac{\langle f(U_{0}-U_{1}+C)\rangle_{1}}{\langle f(U_{1}-U_{0}-C)\rangle_{0}}\exp{(+C)},
	\label{Eq:FEM:BAR:BAR}
\end{equation}
where
\begin{equation}
	C=\ln\frac{Q_{0}n_{1}}{Q_{1}n_{0}},
	\label{Eq:FEM:BAR:C}
\end{equation}
and $f$ denotes the Fermi function
\begin{equation}
	f(x)=\frac{1}{1+\exp{(+x)}}.
\end{equation}
It can also be expressed as\cite{ShirtsPRL2003}
\begin{equation}
	n_1\langle f(U_{0}-U_{1}+C)\rangle_{1}=n_0\langle f(U_{1}-U_{0}-C)\rangle_{0}.
\end{equation}
It should be noted that Eq.~\ref{Eq:FEM:BAR:BAR} is true for any $C$, which is actually a shift for one of the potential function. But the particular value specified in Eq.~\ref{Eq:FEM:BAR:C} minimizes the expected square error given the finite numbers ($n_0$ and $n_1$) of samples.

The variance of $\Delta A$ can be obtained by substituting Eq.~\ref{eq:FEM:BAR:W} into Eq.~\ref{eq:FEM:BAR:expectation}, and is 
\begin{align}
	\delta^2 \Delta A =&\frac{\left<f^2(U_{1}-U_{0}-C)\right>_0}{n_0\left<f(U_{1}-U_{0}-C)\right>_0^2}+\frac{\left<f^2(U_{0}-U_{1}+C)\right>_1}{n_1\left<f(U_{0}-U_{1}+C)\right>_1^2}-\frac{1}{n_0}-\frac{1}{n_1}\notag\\
	=&\left(\int \frac{n_0n_1\rho_0\rho_1}{n_0\rho_0+n_1\rho_1}\diff \mathbf{q}\right)^{-1}-\frac{n_0+n_1}{n_0n_1},
\end{align}
in which $\rho_i=\exp{(-U_i)}/Q_i$ is the probability.